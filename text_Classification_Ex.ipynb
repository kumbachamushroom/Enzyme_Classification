{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [],
   "source": [
    "from nemo.collections import nlp as nemo_nlp\n",
    "from nemo.utils.exp_manager import exp_manager\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from omegaconf import OmegaConf"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [],
   "source": [
    "DATA_DIR = \"DATA_DIR\"\n",
    "WORK_DIR = \"WORK_DIR\"\n",
    "os.environ['DATA_DIR'] = DATA_DIR\n",
    "\n",
    "os.makedirs(WORK_DIR, exist_ok=True)\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [],
   "source": [
    "config = OmegaConf.load('/home/lucas/PycharmProjects/Enzyme_Classification/configs/text_classification_config.yaml')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Train dataloader's config: \n",
      "\n",
      "file_path: /home/lucas/PycharmProjects/Enzyme_Classification/SST-2/train.tsv\n",
      "batch_size: 64\n",
      "shuffle: true\n",
      "num_samples: 5\n",
      "num_workers: ${model.dataset.num_workers}\n",
      "drop_last: ${model.dataset.drop_last}\n",
      "pin_memory: ${model.dataset.pin_memory}\n",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "config.model.dataset.num_classes=2\n",
    "config.model.train_ds.file_path = os.path.join('/home/lucas/PycharmProjects/Enzyme_Classification', 'SST-2/train.tsv')\n",
    "config.model.validation_ds.file_path = os.path.join('/home/lucas/PycharmProjects/Enzyme_Classification', 'SST-2/dev.tsv')\n",
    "# Name of the .nemo file where trained model will be saved.\n",
    "config.save_to = 'trained-model.nemo'\n",
    "config.export_to = 'trained-model.onnx'\n",
    "\n",
    "print(\"Train dataloader's config: \\n\")\n",
    "# OmegaConf.to_yaml() is used to create a proper format for printing the train dataloader's config\n",
    "# You may change other params like batch size or the number of samples to be considered (-1 means all the samples)\n",
    "print(OmegaConf.to_yaml(config.model.train_ds))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Trainer config - \n",
      "\n",
      "gpus: 1\n",
      "num_nodes: 1\n",
      "max_epochs: 100\n",
      "max_steps: null\n",
      "accumulate_grad_batches: 1\n",
      "gradient_clip_val: 0.0\n",
      "amp_level: O0\n",
      "precision: 32\n",
      "accelerator: ddp\n",
      "log_every_n_steps: 1\n",
      "val_check_interval: 1.0\n",
      "resume_from_checkpoint: null\n",
      "num_sanity_val_steps: 0\n",
      "checkpoint_callback: false\n",
      "logger: false\n",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "print(\"Trainer config - \\n\")\n",
    "# OmegaConf.to_yaml() is used to create a proper format for printing the trainer config\n",
    "print(OmegaConf.to_yaml(config.trainer))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# lets modify some trainer configs\n",
    "# checks if we have GPU available and uses it\n",
    "config.trainer.gpus = 1 if torch.cuda.is_available() else 0\n",
    "\n",
    "\n",
    "# for mixed precision training, uncomment the lines below (precision should be set to 16 and amp_level to O1):\n",
    "# config.trainer.precision = 16\n",
    "# config.trainer.amp_level = O1\n",
    "\n",
    "# disable distributed training when using Colab to prevent the errors\n",
    "config.trainer.accelerator = None\n",
    "\n",
    "# setup max number of steps to reduce training time for demonstration purposes of this tutorial\n",
    "# Training stops when max_step or max_epochs is reached (earliest)\n",
    "config.trainer.max_epochs = 5\n",
    "\n",
    "# instantiates a PT Trainer object by using the trainer section of the config\n",
    "trainer = pl.Trainer(**config.trainer)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "[NeMo W 2021-01-15 13:46:41 exp_manager:562] trainer had a weights_save_path of cwd(). This was ignored.\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": [
      "exp_dir: /home/lucas/PycharmProjects/Enzyme_Classification/DATA_DIR\n",
      "name: TextClassification\n",
      "create_tensorboard_logger: true\n",
      "create_checkpoint_callback: true\n",
      "\n",
      "[NeMo I 2021-01-15 13:46:41 exp_manager:183] Experiments will be logged at /home/lucas/PycharmProjects/Enzyme_Classification/DATA_DIR/TextClassification/2021-01-15_13-32-33\n",
      "[NeMo I 2021-01-15 13:46:41 exp_manager:519] TensorboardLogger has been set up\n",
      "/home/lucas/PycharmProjects/Enzyme_Classification/DATA_DIR/TextClassification/2021-01-15_13-32-33\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    " #The experiment manager of a trainer object can not be set twice. We repeat the trainer creation code again here to prevent getting error when this cell is executed more than once. \n",
    "trainer = pl.Trainer(**config.trainer)\n",
    "\n",
    "# exp_dir specifies the path to store the the checkpoints and also the logs, it's default is \"./nemo_experiments\"\n",
    "# You may set it by uncommentig the following line\n",
    "# config.exp_manager.exp_dir = 'LOG_CHECKPOINT_DIR'\n",
    "\n",
    "# OmegaConf.to_yaml() is used to create a proper format for printing the trainer config\n",
    "print(OmegaConf.to_yaml(config.exp_manager))\n",
    "\n",
    "exp_dir = exp_manager(trainer, config.exp_manager)\n",
    "\n",
    "# the exp_dir provides a path to the current experiment for easy access\n",
    "print(exp_dir)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "Using bos_token, but it is not set yet.\n",
      "Using eos_token, but it is not set yet.\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": [
      "[NeMo I 2021-01-15 13:46:43 text_classification_dataset:119] Read 1 examples from /home/lucas/PycharmProjects/Enzyme_Classification/SST-2/train.tsv.\n",
      "[NeMo I 2021-01-15 13:46:43 text_classification_dataset:232] *** Example ***\n",
      "[NeMo I 2021-01-15 13:46:43 text_classification_dataset:233] example 0: ['hide', 'new', 'secretions', 'from', 'the', 'parental', 'units']\n",
      "[NeMo I 2021-01-15 13:46:43 text_classification_dataset:234] subtokens: [CLS] hide new secret ##ions from the parental units [SEP]\n",
      "[NeMo I 2021-01-15 13:46:43 text_classification_dataset:235] input_ids: 101 4750 1207 3318 5266 1121 1103 22467 2338 102\n",
      "[NeMo I 2021-01-15 13:46:43 text_classification_dataset:236] segment_ids: 0 0 0 0 0 0 0 0 0 0\n",
      "[NeMo I 2021-01-15 13:46:43 text_classification_dataset:237] input_mask: 1 1 1 1 1 1 1 1 1 1\n",
      "[NeMo I 2021-01-15 13:46:43 text_classification_dataset:238] label: 0\n",
      "[NeMo I 2021-01-15 13:46:43 data_preprocessing:294] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2021-01-15 13:46:43 data_preprocessing:300] Min: 10 |                  Max: 10 |                  Mean: 10.0 |                  Median: 10.0\n",
      "[NeMo I 2021-01-15 13:46:43 data_preprocessing:302] 75 percentile: 10.00\n",
      "[NeMo I 2021-01-15 13:46:43 data_preprocessing:303] 99 percentile: 10.00\n",
      "[NeMo I 2021-01-15 13:46:43 text_classification_dataset:119] Read 872 examples from /home/lucas/PycharmProjects/Enzyme_Classification/SST-2/dev.tsv.\n",
      "[NeMo I 2021-01-15 13:46:43 text_classification_dataset:232] *** Example ***\n",
      "[NeMo I 2021-01-15 13:46:43 text_classification_dataset:233] example 0: ['it', \"'s\", 'a', 'charming', 'and', 'often', 'affecting', 'journey', '.']\n",
      "[NeMo I 2021-01-15 13:46:43 text_classification_dataset:234] subtokens: [CLS] it ' s a charming and often affecting journey . [SEP]\n",
      "[NeMo I 2021-01-15 13:46:43 text_classification_dataset:235] input_ids: 101 1122 112 188 170 14186 1105 1510 12759 5012 119 102\n",
      "[NeMo I 2021-01-15 13:46:43 text_classification_dataset:236] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "[NeMo I 2021-01-15 13:46:43 text_classification_dataset:237] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "[NeMo I 2021-01-15 13:46:43 text_classification_dataset:238] label: 1\n",
      "[NeMo I 2021-01-15 13:46:43 text_classification_dataset:232] *** Example ***\n",
      "[NeMo I 2021-01-15 13:46:43 text_classification_dataset:233] example 1: ['unflinchingly', 'bleak', 'and', 'desperate']\n",
      "[NeMo I 2021-01-15 13:46:43 text_classification_dataset:234] subtokens: [CLS] un ##f ##lin ##ching ##ly bleak and desperate [SEP]\n",
      "[NeMo I 2021-01-15 13:46:43 text_classification_dataset:235] input_ids: 101 8362 2087 2836 7520 1193 26481 1105 7127 102\n",
      "[NeMo I 2021-01-15 13:46:43 text_classification_dataset:236] segment_ids: 0 0 0 0 0 0 0 0 0 0\n",
      "[NeMo I 2021-01-15 13:46:43 text_classification_dataset:237] input_mask: 1 1 1 1 1 1 1 1 1 1\n",
      "[NeMo I 2021-01-15 13:46:43 text_classification_dataset:238] label: 0\n",
      "[NeMo I 2021-01-15 13:46:44 data_preprocessing:294] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2021-01-15 13:46:44 data_preprocessing:300] Min: 4 |                  Max: 61 |                  Mean: 26.44724770642202 |                  Median: 25.5\n",
      "[NeMo I 2021-01-15 13:46:44 data_preprocessing:302] 75 percentile: 34.00\n",
      "[NeMo I 2021-01-15 13:46:44 data_preprocessing:303] 99 percentile: 53.58\n",
      "[NeMo I 2021-01-15 13:46:44 text_classification_model:222] Dataloader config or file_path for the test is missing, so no data loader for test is created!\n"
     ],
     "output_type": "stream"
    },
    {
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-89-c1ede79fba42>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlanguage_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpretrained_model_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'distilbert-base-cased'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnemo_nlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextClassificationModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_to\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/NeMo_SpeakerVerification/venv/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, train_dataloader, val_dataloaders, datamodule)\u001b[0m\n\u001b[1;32m    454\u001b[0m         \u001b[0;31m# ----------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator_backend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator_connector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_accelerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 456\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m         \u001b[0;31m# ----------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/NeMo_SpeakerVerification/venv/lib/python3.7/site-packages/pytorch_lightning/accelerators/gpu_accelerator.py\u001b[0m in \u001b[0;36msetup\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot_gpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot_gpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# CHOOSE OPTIMIZER\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/NeMo_SpeakerVerification/venv/lib/python3.7/site-packages/pytorch_lightning/utilities/device_dtype_mixin.py\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    128\u001b[0m         \"\"\"\n\u001b[1;32m    129\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__update_properties\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/NeMo_SpeakerVerification/venv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    461\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m         \"\"\"\n\u001b[0;32m--> 463\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/NeMo_SpeakerVerification/venv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/NeMo_SpeakerVerification/venv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/NeMo_SpeakerVerification/venv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/NeMo_SpeakerVerification/venv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    379\u001b[0m                 \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m                     \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/NeMo_SpeakerVerification/venv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    461\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m         \"\"\"\n\u001b[0;32m--> 463\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 86.00 MiB (GPU 0; 3.95 GiB total capacity; 2.51 GiB already allocated; 54.25 MiB free; 2.61 GiB reserved in total by PyTorch)"
     ],
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 86.00 MiB (GPU 0; 3.95 GiB total capacity; 2.51 GiB already allocated; 54.25 MiB free; 2.61 GiB reserved in total by PyTorch)",
     "output_type": "error"
    }
   ],
   "source": [
    "config.model.language_model.pretrained_model_name = 'distilbert-base-cased'\n",
    "model = nemo_nlp.models.TextClassificationModel(cfg=config.model, trainer=trainer)\n",
    "trainer.fit(model)\n",
    "model.save_to(config.save_to)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}